#!/usr/bin/env python3
"""
é‡è¯•æ‰€æœ‰å¤±è´¥çš„ç”¨æˆ· - Nova 01 å’Œ Nova 02
"""

import asyncio
import csv
from datetime import datetime
from pathlib import Path
from scrape_user_tikhub import TikHubUserScraper


async def scrape_single_user(scraper, username: str, index: int, total: int) -> dict:
    """çˆ¬å–å•ä¸ªç”¨æˆ·"""
    print(f"[{index}/{total}] æ­£åœ¨é‡è¯•: @{username}")

    try:
        result = await scraper.fetch_user_profile(unique_id=username)

        if result and result.get('code') == 200:
            user_data = result.get('data', {}).get('user', {})

            row = {
                'username': username,
                'unique_id': user_data.get('unique_id', ''),
                'nickname': user_data.get('nickname', ''),
                'uid': user_data.get('uid', ''),
                'sec_uid': user_data.get('sec_uid', ''),
                'signature': user_data.get('signature', '').replace('\n', ' '),
                'follower_count': user_data.get('follower_count', 0),
                'following_count': user_data.get('following_count', 0),
                'total_favorited': user_data.get('total_favorited', 0),
                'aweme_count': user_data.get('aweme_count', 0),
                'visible_videos_count': user_data.get('visible_videos_count', 0),
                'verification_type': user_data.get('verification_type', 0),
                'verified': 'Yes' if user_data.get('verification_type', 0) > 0 else 'No',
                'bio_email': user_data.get('bio_email', ''),
                'category': user_data.get('category', ''),
                'account_type': user_data.get('account_type', 0),
                'avatar_larger_url': user_data.get('avatar_larger', {}).get('url_list', [''])[0],
                'profile_url': f"https://www.tiktok.com/@{username}",
                'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'scrape_status': 'success',
                'error_message': ''
            }

            print(f"  âœ“ æˆåŠŸ - ç²‰ä¸: {row['follower_count']:,}, è§†é¢‘: {row['aweme_count']}")
            return row

        else:
            row = {
                'username': username,
                'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'scrape_status': 'failed',
                'error_message': result.get('message', 'Unknown error') if result else 'No response'
            }
            print(f"  âœ— å¤±è´¥ - {row['error_message']}")
            return row

    except Exception as e:
        print(f"  âœ— å¼‚å¸¸ - {str(e)}")
        row = {
            'username': username,
            'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'scrape_status': 'error',
            'error_message': str(e)
        }
        return row


async def retry_failed_users(
    failed_users_files: list,
    csv_outputs: list,
    api_token: str,
    api_base_url: str = "https://api.tikhub.io",
    concurrency: int = 10
):
    """é‡è¯•æ‰€æœ‰å¤±è´¥çš„ç”¨æˆ·"""
    print("="*60)
    print("é‡è¯•æ‰€æœ‰å¤±è´¥ç”¨æˆ· - Nova 01 & Nova 02")
    print("="*60)
    print()

    # è¯»å–æ‰€æœ‰å¤±è´¥ç”¨æˆ·
    all_failed_usernames = []
    for failed_file in failed_users_files:
        if Path(failed_file).exists():
            with open(failed_file, 'r', encoding='utf-8') as f:
                usernames = [line.strip() for line in f if line.strip()]
                all_failed_usernames.extend(usernames)
                print(f"âœ“ {failed_file}: {len(usernames)} ä¸ªå¤±è´¥ç”¨æˆ·")

    print(f"\nâœ“ æ€»è®¡éœ€è¦é‡è¯•: {len(all_failed_usernames)} ä¸ªç”¨æˆ·")
    print(f"âœ“ å¹¶å‘æ•°: {concurrency} ä¸ªè¯·æ±‚åŒæ—¶è¿›è¡Œ")
    print(f"âœ“ é¢„è®¡å®Œæˆæ—¶é—´: ~{len(all_failed_usernames)/concurrency:.1f} ç§’ ({len(all_failed_usernames)/concurrency/60:.1f} åˆ†é’Ÿ)")
    print()

    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    scraper = TikHubUserScraper(
        api_token=api_token,
        base_url=api_base_url
    )

    # CSV å­—æ®µ
    csv_fields = [
        'username',
        'unique_id',
        'nickname',
        'uid',
        'sec_uid',
        'signature',
        'follower_count',
        'following_count',
        'total_favorited',
        'aweme_count',
        'visible_videos_count',
        'verification_type',
        'verified',
        'bio_email',
        'category',
        'account_type',
        'avatar_larger_url',
        'profile_url',
        'scrape_time',
        'scrape_status',
        'error_message'
    ]

    print("å¼€å§‹é‡è¯•...")
    print("-"*60)

    # ä½¿ç”¨ Semaphore é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(concurrency)

    async def scrape_with_semaphore(username, index, total):
        async with semaphore:
            return await scrape_single_user(scraper, username, index, total)

    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = [
        scrape_with_semaphore(username, i+1, len(all_failed_usernames))
        for i, username in enumerate(all_failed_usernames)
    ]

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks)

    print("-"*60)
    print()

    # æŒ‰ç”¨æˆ·ååˆ†ç»„ç»“æœï¼Œç”¨äºæ›´æ–°å¯¹åº”çš„ CSV
    results_by_username = {r['username']: r for r in results}

    # æ›´æ–°æ¯ä¸ª CSV æ–‡ä»¶
    for csv_file in csv_outputs:
        csv_path = Path(csv_file)
        if not csv_path.exists():
            print(f"âš  CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            continue

        print(f"æ›´æ–° CSV æ–‡ä»¶: {csv_file}")

        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = {}
        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                existing_data[row['username']] = row

        # æ›´æ–°æˆåŠŸçš„è®°å½•
        updated_count = 0
        for username, result in results_by_username.items():
            if username in existing_data and result.get('scrape_status') == 'success':
                existing_data[username] = result
                updated_count += 1

        # å†™å› CSV
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=csv_fields, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(existing_data.values())

        print(f"  âœ“ æ›´æ–°äº† {updated_count} æ¡è®°å½•")

        # ç»Ÿè®¡è¯¥ CSV çš„æˆåŠŸç‡
        total_success = sum(1 for r in existing_data.values() if r.get('scrape_status') == 'success')
        print(f"  âœ“ æ€»æˆåŠŸç‡: {total_success}/{len(existing_data)} ({total_success/len(existing_data)*100:.1f}%)")
        print()

    # æ€»ä½“ç»Ÿè®¡
    success_count = sum(1 for r in results if r.get('scrape_status') == 'success')
    failed_count = len(results) - success_count

    print("="*60)
    print("é‡è¯•ç»Ÿè®¡")
    print("="*60)
    print(f"é‡è¯•æ€»æ•°: {len(results)}")
    print(f"æœ¬æ¬¡æˆåŠŸ: {success_count}")
    print(f"ä»ç„¶å¤±è´¥: {failed_count}")
    print(f"æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
    print()

    # ä¿å­˜ä»ç„¶å¤±è´¥çš„ç”¨æˆ·
    still_failed = [r['username'] for r in results if r.get('scrape_status') != 'success']
    if still_failed:
        with open('still_failed_users_final.txt', 'w') as f:
            f.write('\n'.join(still_failed))
        print(f"ä»ç„¶å¤±è´¥çš„ç”¨æˆ·å·²ä¿å­˜åˆ°: still_failed_users_final.txt ({len(still_failed)}ä¸ª)")
    else:
        print("ğŸ‰ æ‰€æœ‰ç”¨æˆ·éƒ½æˆåŠŸçˆ¬å–ï¼")

    print("="*60)


async def main():
    """ä¸»å‡½æ•°"""
    FAILED_USERS_FILES = [
        "/Users/jiajun/tiktok_user_scrape/still_failed_users.txt",  # Nova 01
        "/Users/jiajun/tiktok_user_scrape/failed_users_nova02_final.txt"  # Nova 02
    ]

    CSV_OUTPUTS = [
        "/Users/jiajun/tiktok_user_scrape/output/nova01_users.csv",
        "/Users/jiajun/tiktok_user_scrape/output/nova02_users.csv"
    ]

    API_TOKEN = "YOUR_API_TOKEN_HERE"
    API_BASE_URL = "https://api.tikhub.io"
    CONCURRENCY = 10  # åŒæ—¶ 10 ä¸ªè¯·æ±‚

    await retry_failed_users(
        failed_users_files=FAILED_USERS_FILES,
        csv_outputs=CSV_OUTPUTS,
        api_token=API_TOKEN,
        api_base_url=API_BASE_URL,
        concurrency=CONCURRENCY
    )


if __name__ == "__main__":
    asyncio.run(main())
